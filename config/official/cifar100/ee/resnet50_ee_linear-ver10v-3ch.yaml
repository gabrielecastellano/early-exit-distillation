dataset:
    name: &dataset_name 'cifar100'
    root: &data_dir './resource/data/cifar100/'
    data:
        train: !join [*data_dir, 'train.txt']
        valid: !join [*data_dir, 'valid.txt']
        test: !join [*data_dir, 'valid.txt']
    num_workers: 16
    normalizer:
        mean: [0.5070751592371323, 0.48654887331495095, 0.4409178433670343]
        std: [0.2673342858792401, 0.2564384629170883, 0.27615047132568404]

input_shape: [3, 32, 32]

teacher_model:
    config: './config/official/cifar100/org/resnet50_32.yaml'
    extract_designed_module: False
    start_idx: 0
    end_idx: 11 # 7, 15, 55 for vers. 1, 2, 3

student_model:
    type: &smodel_type 'resnet50_head_mimic'
    version: &ver '10v'
    params:
        bottleneck_channels: &bottleneck_channels 3
    experiment: &distill_experiment !join [*dataset_name, '-', *smodel_type, '-ver', *ver, '-', *bottleneck_channels, 'ch']
    ckpt: !join ['./resource/ckpt/hnd/', *distill_experiment, '-joint_linear.pt']

mimic_model:
    type: &mmodel_type 'resnet50_mimic'
    experiment: &mimic_experiment !join [*dataset_name, '-', *mmodel_type, '-ver', *ver, '-', *bottleneck_channels, 'ch']
    ckpt: !join ['./resource/ckpt/hnd/', *mimic_experiment, '-joint_linear.pt']

ee_model:
    type: &eemodel_type 'linear'
    experiment: &ee_experiment !join [*dataset_name, '-', *mmodel_type, '-ver', *ver, '-', *bottleneck_channels, 'ch', '-', *eemodel_type]
    params:
        epoch: 30
        labels_subsets: [100] #[5, 10, 20, 50, 100]
        batch_size: 64
        joint_loss_coefficients:
            mimic: 0.01
            classification: 2
            regularization: 2
        optimizer:
            type: 'Adam'
            params:
                lr: 0.001
        scheduler:
            type: 'MultiStepLR'
            params:
                milestones: [ 7, 15, 22 ]
                gamma: 0.1
        criterion:
            type: 'CrossEntropyLoss'
            params:
                reduction: 'sum'
    # threshold: [0.8]
    # thresholds: [0, 0.8, 0.9, 0.92, 0.95, 0.98] #[0.6, 0.7, 0.8, 0.9, 0.95]
    # thresholds: [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.93, 0.95, 0.97, 0.99, 1.0]
    thresholds: [0, 0.9, 0.93, 0.95, 0.97, 0.99, 1.0]
    load_embeddings: True
    store_embeddings: False
    shuffle_train_set: True
    device: 'cuda'
    storage: !join ['./resource/embeddings/', *dataset_name, '-', *mmodel_type, '-ver', *ver, '-', *bottleneck_channels, 'ch']
    samples_fraction: 1.0
    instance_name: &instance_name !join [*ee_experiment, '_', '{}classes', '_', '{}per-class', '_', 't{}']
    ckpt: !join ['./resource/ckpt/ee/', *instance_name, '_joint.sav']

train_distill:
    epoch: 30
    batch_size: 64
    rough_size: 256
    interval: -1
    optimizer:
        type: 'Adam'
        params:
            lr: 0.001
    scheduler:
        type: 'MultiStepLR'
        params:
            milestones: [10, 20, 25]
            gamma: 0.1
    criterion:
        type: 'MSELoss'
        params:
            reduction: 'sum'

train_finetune:
    epoch: 30
    batch_size: 64
    rough_size: 256
    interval: -1
    optimizer:
        type: 'Adam'
        params:
            lr: 0.00001
    scheduler:
        type: 'MultiStepLR'
        params:
            milestones: [10, 20]
            gamma: 0.1
    criterion:
        type: 'CrossEntropyLoss'
        params:
            reduction: 'sum'

test:
    batch_size: 64